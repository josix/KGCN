U-I Graph:
number of users: 138,287
number of items: 27,235
number of interactions: 19,972,998

KG:
number of entities (containing items): 9,853,895
number of relations: 14
number of KG triples: 50,286,430
CTR:
train auc: 0.9949  f1: 0.9693    eval auc: 0.9771  f1: 0.9320    test auc: 0.9772  f1: 0.9320
top-k:     k=1    k=2     k=5     k=10    k=20    k=50    k=100
precision: 0.0600	0.0550	0.0500	0.0500	0.0540	0.0488	0.0411	
recall: 0.0031	0.0057	0.0129	0.0337	0.0850	0.2077	0.3181	
time used: 12404 s

epoch 0    train auc: 0.9731  f1: 0.9199    eval auc: 0.9692  f1: 0.9157    test auc: 0.9693  f1: 0.9158
epoch 1    train auc: 0.9827  f1: 0.9388    eval auc: 0.9760  f1: 0.9292    test auc: 0.9761  f1: 0.9294
epoch 2    train auc: 0.9881  f1: 0.9499    eval auc: 0.9787  f1: 0.9336    test auc: 0.9789  f1: 0.9340
epoch 3    train auc: 0.9906  f1: 0.9560    eval auc: 0.9787  f1: 0.9344    test auc: 0.9789  f1: 0.9346
epoch 4    train auc: 0.9921  f1: 0.9599    eval auc: 0.9784  f1: 0.9337    test auc: 0.9786  f1: 0.9340
epoch 5    train auc: 0.9931  f1: 0.9629    eval auc: 0.9782  f1: 0.9330    test auc: 0.9784  f1: 0.9333
epoch 6    train auc: 0.9938  f1: 0.9652    eval auc: 0.9779  f1: 0.9327    test auc: 0.9780  f1: 0.9329
epoch 7    train auc: 0.9943  f1: 0.9670    eval auc: 0.9776  f1: 0.9326    test auc: 0.9777  f1: 0.9327
epoch 8    train auc: 0.9947  f1: 0.9683    eval auc: 0.9774  f1: 0.9318    test auc: 0.9775  f1: 0.9320
epoch 9    train auc: 0.9949  f1: 0.9693    eval auc: 0.9771  f1: 0.9320    test auc: 0.9772  f1: 0.9320

precision: 0.1900	0.1400	0.1040	0.0810	0.0675	0.0478	0.0387	
precision: 0.1500	0.1650	0.1180	0.0920	0.0780	0.0572	0.0466	
precision: 0.1200	0.0950	0.0820	0.0840	0.0850	0.0632	0.0481	
precision: 0.0600	0.0550	0.0740	0.0690	0.0605	0.0542	0.0446	
precision: 0.0500	0.0550	0.0680	0.0550	0.0580	0.0548	0.0462	
precision: 0.0600	0.0450	0.0420	0.0490	0.0575	0.0536	0.0472	
precision: 0.0500	0.0400	0.0560	0.0530	0.0500	0.0518	0.0443	
precision: 0.0600	0.0650	0.0560	0.0520	0.0585	0.0526	0.0432	
precision: 0.0900	0.0750	0.0540	0.0600	0.0525	0.0472	0.0396	
precision: 0.0600	0.0550	0.0500	0.0500	0.0540	0.0488	0.0411	

recall: 0.0250	0.0291	0.0434	0.0628	0.1252	0.2051	0.3035	
recall: 0.0246	0.0351	0.0525	0.0748	0.1457	0.2418	0.3676	
recall: 0.0101	0.0144	0.0378	0.0620	0.1495	0.2451	0.3564	
recall: 0.0121	0.0140	0.0283	0.0505	0.1087	0.2287	0.3549	
recall: 0.0131	0.0176	0.0288	0.0428	0.1132	0.2328	0.3838	
recall: 0.0043	0.0061	0.0202	0.0498	0.1050	0.2504	0.3885	
recall: 0.0156	0.0166	0.0290	0.0491	0.0965	0.2111	0.3778	
recall: 0.0129	0.0183	0.0272	0.0497	0.1111	0.2037	0.3537	
recall: 0.0046	0.0170	0.0319	0.0577	0.1039	0.2047	0.3245	
recall: 0.0031	0.0057	0.0129	0.0337	0.0850	0.2077	0.3181	

